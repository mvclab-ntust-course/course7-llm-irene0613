{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recitation on Development Infrastructure and PyTorch Tutorial\n",
        "\n",
        "## Contents\n",
        "1. Google Colab Basics\n",
        "2. GPU Environment in Colab\n",
        "3. Introduction to PyTorch\n",
        "4. Python Debugging Tools"
      ],
      "metadata": {
        "id": "OU0Kz1xCObIq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewh2URgYOUrZ",
        "outputId": "086d2c23-cc5b-4eb9-ed15-4d09d3cff467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "### 1. Google Colab Basics\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "for path in Path('/content/drive/MyDrive/').glob(\"*\"):\n",
        "  print(path)"
      ],
      "metadata": {
        "id": "PDY9698FRo1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch\n",
        "# !pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MCQ2ZztQ6Z6",
        "outputId": "54d73d17-5b1e-4a57-aebc-58023f8fa13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.0.1+cu118\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, jinja2, networkx, sympy, triton, typing-extensions\n",
            "Required-by: fastai, torchaudio, torchdata, torchtext, torchvision, triton\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability with PyTorch\n",
        "import torch\n",
        "\n",
        "print(\"Is CUDA available?\", torch.cuda.is_available())\n",
        "print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# Check GPU details with nvidia-smi\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFpIA5MpOZd3",
        "outputId": "4574b868-5ba3-44e7-d75e-4d92bcf4ed5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is CUDA available? True\n",
            "GPU name: Tesla T4\n",
            "Mon Sep  4 08:20:40 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1D Array"
      ],
      "metadata": {
        "id": "39jHE-2DRgth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# return evenly spaced values within a given interval\n",
        "#生成給定範圍內的等間距值\n",
        "#torch.arange(10) 創建了一個張量，包含從 0 到 9 的整數，總共 10 個值\n",
        "#arange 函數類似於 Python 的內建函數 range，但是返回的是一個 PyTorch 張量。\n",
        "range_arr_torch = torch.arange(10)\n",
        "print(\"An array given range is \\n\", range_arr_torch, \" with dimensions \", range_arr_torch.shape, \"\\n\")\n",
        "\n",
        "# return evenly spaced numbers over a specified interval\n",
        "#生成在指定區間內的等間距數字\n",
        "#torch.linspace(2.0, 3.0, steps=5) 創建了一個張量，包含在 2.0 到 3.0 之間的 5 個等間距的數值。\n",
        "#linspace 函數類似於 NumPy 的 linspace 函數，用於在指定的區間內生成等間距的數字。\n",
        "linspace_arr_torch = torch.linspace(2.0, 3.0, steps=5)\n",
        "print(\"An evenly spaced array given range is \\n\", linspace_arr_torch, \" with dimensions \", linspace_arr_torch.shape, \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEN6Nf4ORQwn",
        "outputId": "8d94f62e-399a-41a7-9c5b-1991f2e50a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An array given range is \n",
            " tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])  with dimensions  torch.Size([10]) \n",
            "\n",
            "An evenly spaced array given range is \n",
            " tensor([2.0000, 2.2500, 2.5000, 2.7500, 3.0000])  with dimensions  torch.Size([5]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor with uniform distribution between 0 and 1\n",
        "# 創建一個包含從均勻分佈 (0,1) 中取樣的隨機值的張量\n",
        "#rand 函數返回一個張量，其元素在區間 [0, 1) 上均勻分佈。\n",
        "uniform_tensor = torch.rand(10)\n",
        "print(\"Random tensor with elements sampled from a Uniform(0,1) distribution: \\n\", uniform_tensor, \"\\n with dimensions \", uniform_tensor.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7YVwXxtSgdw",
        "outputId": "4d531918-3eaa-4ace-caa3-08d20c9f8151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random tensor with elements sampled from a Uniform(0,1) distribution: \n",
            " tensor([0.1535, 0.7466, 0.5822, 0.4902, 0.9192, 0.3945, 0.4524, 0.3335, 0.7886,\n",
            "        0.0129]) \n",
            " with dimensions  torch.Size([10]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random tensor with normal distribution (mean=0, std=1)\n",
        "# 創建一個包含從標準正態分佈 (mean=0, std=1) 中取樣的隨機值的張量\n",
        "#randn 函數返回一個張量，其元素在正態分佈中取樣，均值為 0，標準差為 1。(代表值在-1~1之間)\n",
        "randn_tensor = torch.randn(10)\n",
        "print(\"Random tensor with elements sampled from a N(0,1) distribution: \\n\", randn_tensor, \"\\n with dimensions \", randn_tensor.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tt-H4EhTAvH",
        "outputId": "4bf01192-8d1a-4f4e-ca2b-c2889bfee89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random tensor with elements sampled from a N(0,1) distribution: \n",
            " tensor([ 0.1584, -0.9019,  0.9327,  0.6437, -0.6493,  0.3706,  0.0977, -0.9473,\n",
            "         0.2808,  0.5418]) \n",
            " with dimensions  torch.Size([10]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor with all ones\n",
        "ones_tensor = torch.ones(10)\n",
        "print(\"Tensor with all elements set to 1: \\n\", ones_tensor, \"\\n with dimensions \", ones_tensor.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rkqIh8WTAsb",
        "outputId": "0f050539-a431-4e54-805e-f4881b5b2484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor with all elements set to 1: \n",
            " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]) \n",
            " with dimensions  torch.Size([10]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor with all zeros\n",
        "#全0的陣列\n",
        "zeros_tensor = torch.zeros(10)\n",
        "print(\"Tensor with all elements set to 0: \\n\", zeros_tensor, \"\\n with dimensions \", zeros_tensor.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6eg8-UyTAp8",
        "outputId": "2bbbaa76-628b-44a5-9e28-5e67049a928f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor with all elements set to 0: \n",
            " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) \n",
            " with dimensions  torch.Size([10]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor from list\n",
        "list_tensor = torch.tensor([1, 2, 3, 4, 5])\n",
        "print(\"Tensor created from a list: \\n\", list_tensor, \"\\n with dimensions \", list_tensor.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu5YIfGATAnk",
        "outputId": "a555b124-4ff6-459c-f286-39e7190d66a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor created from a list: \n",
            " tensor([1, 2, 3, 4, 5]) \n",
            " with dimensions  torch.Size([5]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning a tensor\n",
        "cloned_tensor = list_tensor.clone()\n",
        "print(\"Cloned tensor: \\n\", cloned_tensor, \"\\n with dimensions \", cloned_tensor.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WbV3GiyTAkj",
        "outputId": "78a8333b-244b-4072-8871-6b8681d66bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloned tensor: \n",
            " tensor([1, 2, 3, 4, 5]) \n",
            " with dimensions  torch.Size([5]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor with no autograd tracking\n",
        "#torch.no_grad()：这个上下文管理器禁止在其内部进行任何操作时计算梯度。\n",
        "with torch.no_grad():\n",
        "    no_grad_tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
        "print(\"Tensor with no autograd tracking: \\n\", no_grad_tensor, \"\\n with dimensions \", no_grad_tensor.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtowwdAZTAdX",
        "outputId": "9e63c845-14c9-4050-8056-2a3ab572a892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor with no autograd tracking: \n",
            " tensor([1., 2., 3.]) \n",
            " with dimensions  torch.Size([3]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor with requires_grad=True\n",
        "#創建一個張量，數據類型為 float32，並且啟用了梯度追踪。\n",
        "grad_tensor = torch.tensor([1, 2, 3], dtype=torch.float32, requires_grad=True)\n",
        "print(\"Tensor with requires_grad=True: \\n\", grad_tensor, \"\\n with dimensions \", grad_tensor.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwQt1uGFTF_V",
        "outputId": "8920f74b-fd05-4e59-e3ac-5775d8a28e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor with requires_grad=True: \n",
            " tensor([1., 2., 3.], requires_grad=True) \n",
            " with dimensions  torch.Size([3]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Dimensional Tensor"
      ],
      "metadata": {
        "id": "9WdXHWXtT0di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor with all zeros (shape: 3x4)\n",
        "zeros_tensor = torch.zeros(3, 4)\n",
        "print(\"Tensor with all elements set to 0: \\n\", zeros_tensor, \"\\n with dimensions \", zeros_tensor.shape, \"\\n\")\n",
        "\n",
        "# Tensor with all ones (shape: 3x4)\n",
        "ones_tensor = torch.ones(3, 4)\n",
        "print(\"Tensor with all elements set to 1: \\n\", ones_tensor, \"\\n with dimensions \", ones_tensor.shape, \"\\n\")\n",
        "\n",
        "# Tensor with all elements set to a specific value, e.g., 7 (shape: 3x4)\n",
        "full_tensor = torch.full((3, 4), 7)\n",
        "print(\"Tensor with all elements set to a specific value (7): \\n\", full_tensor, \"\\n with dimensions \", full_tensor.shape, \"\\n\")\n",
        "\n",
        "# Tensor with random values sampled from a uniform distribution between 0 and 1 (shape: 3x4)\n",
        "rand_tensor = torch.rand(3, 4)\n",
        "print(\"Random tensor with elements sampled from a Uniform(0,1) distribution: \\n\", rand_tensor, \"\\n with dimensions \", rand_tensor.shape, \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQdfW8F1TF4H",
        "outputId": "461934f2-cf2b-4b32-a8af-2e541cf5ce7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor with all elements set to 0: \n",
            " tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]]) \n",
            " with dimensions  torch.Size([3, 4]) \n",
            "\n",
            "Tensor with all elements set to 1: \n",
            " tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]]) \n",
            " with dimensions  torch.Size([3, 4]) \n",
            "\n",
            "Tensor with all elements set to a specific value (7): \n",
            " tensor([[7, 7, 7, 7],\n",
            "        [7, 7, 7, 7],\n",
            "        [7, 7, 7, 7]]) \n",
            " with dimensions  torch.Size([3, 4]) \n",
            "\n",
            "Random tensor with elements sampled from a Uniform(0,1) distribution: \n",
            " tensor([[0.4410, 0.8624, 0.9225, 0.9108],\n",
            "        [0.3641, 0.2494, 0.0717, 0.1293],\n",
            "        [0.9618, 0.2327, 0.2088, 0.8742]]) \n",
            " with dimensions  torch.Size([3, 4]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Existing tensor (shape: 300x400)\n",
        "existing_tensor = torch.rand(300, 400)\n",
        "\n",
        "# Tensor with all zeros, having the same shape as the existing large tensor\n",
        "zeros_like_tensor = torch.zeros_like(existing_tensor)\n",
        "print(\"Tensor with all elements set to 0, like the existing large tensor: \\n\", zeros_like_tensor, \"\\n with dimensions \", zeros_like_tensor.shape, \"\\n\")\n",
        "\n",
        "# Tensor with all ones, having the same shape as the existing large tensor\n",
        "ones_like_tensor = torch.ones_like(existing_tensor)\n",
        "print(\"Tensor with all elements set to 1, like the existing large tensor: \\n\", ones_like_tensor, \"\\n with dimensions \", ones_like_tensor.shape, \"\\n\")\n",
        "\n",
        "# Tensor with all elements set to a specific value, e.g., 7, having the same shape as the existing large tensor\n",
        "full_like_tensor = torch.full_like(existing_tensor, 7)\n",
        "print(\"Tensor with all elements set to a specific value (7), like the existing large tensor: \\n\", full_like_tensor, \"\\n with dimensions \", full_like_tensor.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A162rhcBTF1h",
        "outputId": "f7c358bd-cc15-47fb-cdca-9d221ca4f449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor with all elements set to 0, like the existing large tensor: \n",
            " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]) \n",
            " with dimensions  torch.Size([300, 400]) \n",
            "\n",
            "Tensor with all elements set to 1, like the existing large tensor: \n",
            " tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        ...,\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.]]) \n",
            " with dimensions  torch.Size([300, 400]) \n",
            "\n",
            "Tensor with all elements set to a specific value (7), like the existing large tensor: \n",
            " tensor([[7., 7., 7.,  ..., 7., 7., 7.],\n",
            "        [7., 7., 7.,  ..., 7., 7., 7.],\n",
            "        [7., 7., 7.,  ..., 7., 7., 7.],\n",
            "        ...,\n",
            "        [7., 7., 7.,  ..., 7., 7., 7.],\n",
            "        [7., 7., 7.,  ..., 7., 7., 7.],\n",
            "        [7., 7., 7.,  ..., 7., 7., 7.]]) \n",
            " with dimensions  torch.Size([300, 400]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a NumPy ndarray (shape: 3x4)\n",
        "ndarray = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "\n",
        "# Create a PyTorch tensor from the NumPy ndarray\n",
        "tensor_from_ndarray = torch.tensor(ndarray)\n",
        "print(\"Tensor created from a NumPy ndarray: \\n\", tensor_from_ndarray, \"\\n with dimensions \", tensor_from_ndarray.shape, \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94WlxtnFUb90",
        "outputId": "2314b2bb-593c-47b7-8f38-28574aa5b708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor created from a NumPy ndarray: \n",
            " tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]]) \n",
            " with dimensions  torch.Size([3, 4]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an example tensor (shape: 3x4)\n",
        "x = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "\n",
        "# Get dimensions of tensor x\n",
        "print(\"Size of x: \", x.size(), \"\\n\")\n",
        "\n",
        "# Concatenate tensors (example: along dimension 0)\n",
        "tensor_seq = [torch.tensor([13, 14, 15, 16]), torch.tensor([17, 18, 19, 20])]\n",
        "x_cat = torch.cat(tensor_seq, dim=0)\n",
        "print(\"Concatenated tensor x_cat: \\n\", x_cat, \"\\n with dimensions \", x_cat.shape, \"\\n\")\n",
        "\n",
        "# Reshape tensor\n",
        "y_reshape = x.view(2, 6)\n",
        "print(\"Reshaped tensor y: \\n\", y_reshape, \"\\n with dimensions \", y_reshape.shape, \"\\n\")\n",
        "\n",
        "# Reshape with inferred dimension\n",
        "y_infer = x.view(-1, 6)\n",
        "print(\"Reshaped tensor with inferred dimension y: \\n\", y_infer, \"\\n with dimensions \", y_infer.shape, \"\\n\")\n",
        "\n",
        "# Transpose tensor\n",
        "y_transpose = x.transpose(0, 1)\n",
        "print(\"Transposed tensor y: \\n\", y_transpose, \"\\n with dimensions \", y_transpose.shape, \"\\n\")\n",
        "\n",
        "# Permute dimensions\n",
        "y_permute = x.permute(1, 0)\n",
        "print(\"Permuted tensor y: \\n\", y_permute, \"\\n with dimensions \", y_permute.shape, \"\\n\")\n",
        "\n",
        "# Add dimension\n",
        "y_unsqueeze = x.unsqueeze(dim=0)\n",
        "print(\"Unsqueezed tensor y: \\n\", y_unsqueeze, \"\\n with dimensions \", y_unsqueeze.shape, \"\\n\")\n",
        "\n",
        "# Add dimension at specified index\n",
        "y_unsqueeze_specific = x.unsqueeze(dim=2)\n",
        "print(\"Specifically unsqueezed tensor y: \\n\", y_unsqueeze_specific, \"\\n with dimensions \", y_unsqueeze_specific.shape, \"\\n\")\n",
        "\n",
        "# Remove dimensions of size 1\n",
        "y_squeeze = y_unsqueeze_specific.squeeze()\n",
        "print(\"Squeezed tensor y: \\n\", y_squeeze, \"\\n with dimensions \", y_squeeze.shape, \"\\n\")\n",
        "\n",
        "# Remove specified dimensions of size 1\n",
        "y_squeeze_specific = y_unsqueeze_specific.squeeze(dim=2)\n",
        "print(\"Specifically squeezed tensor y: \\n\", y_squeeze_specific, \"\\n with dimensions \", y_squeeze_specific.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A5vIhWOUx7K",
        "outputId": "c940417b-0333-4ba9-ff2b-e3bfa6f93265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of x:  torch.Size([3, 4]) \n",
            "\n",
            "Concatenated tensor x_cat: \n",
            " tensor([13, 14, 15, 16, 17, 18, 19, 20]) \n",
            " with dimensions  torch.Size([8]) \n",
            "\n",
            "Reshaped tensor y: \n",
            " tensor([[ 1,  2,  3,  4,  5,  6],\n",
            "        [ 7,  8,  9, 10, 11, 12]]) \n",
            " with dimensions  torch.Size([2, 6]) \n",
            "\n",
            "Reshaped tensor with inferred dimension y: \n",
            " tensor([[ 1,  2,  3,  4,  5,  6],\n",
            "        [ 7,  8,  9, 10, 11, 12]]) \n",
            " with dimensions  torch.Size([2, 6]) \n",
            "\n",
            "Transposed tensor y: \n",
            " tensor([[ 1,  5,  9],\n",
            "        [ 2,  6, 10],\n",
            "        [ 3,  7, 11],\n",
            "        [ 4,  8, 12]]) \n",
            " with dimensions  torch.Size([4, 3]) \n",
            "\n",
            "Permuted tensor y: \n",
            " tensor([[ 1,  5,  9],\n",
            "        [ 2,  6, 10],\n",
            "        [ 3,  7, 11],\n",
            "        [ 4,  8, 12]]) \n",
            " with dimensions  torch.Size([4, 3]) \n",
            "\n",
            "Unsqueezed tensor y: \n",
            " tensor([[[ 1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8],\n",
            "         [ 9, 10, 11, 12]]]) \n",
            " with dimensions  torch.Size([1, 3, 4]) \n",
            "\n",
            "Specifically unsqueezed tensor y: \n",
            " tensor([[[ 1],\n",
            "         [ 2],\n",
            "         [ 3],\n",
            "         [ 4]],\n",
            "\n",
            "        [[ 5],\n",
            "         [ 6],\n",
            "         [ 7],\n",
            "         [ 8]],\n",
            "\n",
            "        [[ 9],\n",
            "         [10],\n",
            "         [11],\n",
            "         [12]]]) \n",
            " with dimensions  torch.Size([3, 4, 1]) \n",
            "\n",
            "Squeezed tensor y: \n",
            " tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]]) \n",
            " with dimensions  torch.Size([3, 4]) \n",
            "\n",
            "Specifically squeezed tensor y: \n",
            " tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]]) \n",
            " with dimensions  torch.Size([3, 4]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 3D tensor (shape: 2x3x4)\n",
        "x_3d = torch.tensor([[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]],\n",
        "                     [[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]])\n",
        "\n",
        "# Get dimensions of 3D tensor x_3d\n",
        "print(\"Size of x_3d: \", x_3d.size(), \"\\n\")\n",
        "\n",
        "# Transpose 3D tensor (swap dimensions 0 and 1)\n",
        "#交換0和1的dim\n",
        "y_transpose_3d = x_3d.transpose(0, 1)\n",
        "print(\"Transposed 3D tensor y: \\n\", y_transpose_3d, \"\\n with dimensions \", y_transpose_3d.shape, \"\\n\")\n",
        "\n",
        "# Permute dimensions of 3D tensor (new order: 1, 0, 2)\n",
        "# 重新排列3D張量的維度（新順序：1, 0, 2）\n",
        "y_permute_3d = x_3d.permute(1, 0, 2)\n",
        "print(\"Permuted 3D tensor y: \\n\", y_permute_3d, \"\\n with dimensions \", y_permute_3d.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjpKvuT_WfpK",
        "outputId": "9a7dadb4-731e-4143-df59-368d2675fcc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of x_3d:  torch.Size([2, 3, 4]) \n",
            "\n",
            "Transposed 3D tensor y: \n",
            " tensor([[[ 1,  2,  3,  4],\n",
            "         [13, 14, 15, 16]],\n",
            "\n",
            "        [[ 5,  6,  7,  8],\n",
            "         [17, 18, 19, 20]],\n",
            "\n",
            "        [[ 9, 10, 11, 12],\n",
            "         [21, 22, 23, 24]]]) \n",
            " with dimensions  torch.Size([3, 2, 4]) \n",
            "\n",
            "Permuted 3D tensor y: \n",
            " tensor([[[ 1,  2,  3,  4],\n",
            "         [13, 14, 15, 16]],\n",
            "\n",
            "        [[ 5,  6,  7,  8],\n",
            "         [17, 18, 19, 20]],\n",
            "\n",
            "        [[ 9, 10, 11, 12],\n",
            "         [21, 22, 23, 24]]]) \n",
            " with dimensions  torch.Size([3, 2, 4]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debugging in Python\n",
        "* Syntax Error -> ChatGPT\n",
        "* Runtime Error -> IPython pdb (ipdb)\n",
        "* Tensor Error -> ipdb\n",
        "* GPU-related Error -> Next Recitation"
      ],
      "metadata": {
        "id": "HlGMfaHCzwyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipdb\n",
        "import ipdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfSk2zdq0UHK",
        "outputId": "89b1f89f-5b78-4930-d01c-e9152136bb32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipdb in /usr/local/lib/python3.10/dist-packages (0.13.13)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.10/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from ipdb) (2.0.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.19.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 常用的 ipdb 指令解釋：\n",
        "\n",
        "- `n`（next）：繼續執行，直到達到當前函數中的下一行，或者它返回。\n",
        "- `c`（continue）：繼續執行，僅在遇到斷點時停止。\n",
        "- `q`（quit）：退出調試器和程序。\n",
        "- `p`（print）：評估並列印表達式。\n",
        "- `l`（list）：列出當前文件的源代碼。\n",
        "- `s`（step）：執行當前行，並在第一個可能的場合停止（例如，在一個函數呼叫中）。"
      ],
      "metadata": {
        "id": "C206Qt_e0j6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用 `ipdb` 的方法有多種，以下是一些常見的使用案例：\n",
        "\n",
        "1. **啟動調試模式**：直接在命令行中輸入以下指令來啟動 `ipdb` 調試模式。\n",
        "    ```bash\n",
        "    python -m ipdb your_script.py\n",
        "    ```\n",
        "    這會在腳本的開始處暫停執行，允許你逐步執行代碼。\n",
        "\n",
        "2. **自動繼續執行**：如果你只想在設置了斷點（breakpoint）的地方暫停，則可以使用以下指令：\n",
        "    ```bash\n",
        "    python -m ipdb -c continue your_script.py\n",
        "    ```\n",
        "    使用 `-c continue` 會讓腳本在啟動後自動繼續執行，直到達到第一個斷點或是報錯點。\n",
        "\n",
        "3. **指定執行參數**：如果你的腳本需要傳入參數，可以這麼做：\n",
        "    ```bash\n",
        "    python -m ipdb your_script.py --your-arg value\n",
        "    ```\n",
        "    只需正常地將參數放在腳本名稱後面即可\n",
        "\n",
        "4. **使用條件斷點**：在你的腳本中，你可以添加 `ipdb.set_trace()` 方法來設置斷點。要讓斷點有條件地觸發，可以這樣使用：\n",
        "    ```python\n",
        "    if some_condition:\n",
        "        ipdb.set_trace()\n",
        "    ```\n",
        "5. **例外時自動觸發調試**：如果你希望只在出現未捕獲的例外（exception）時啟動 `ipdb`，可以使用 `ipdb.launch_ipdb_on_exception()` 上下文管理器。這在嘗試調試偶爾出錯的代碼時特別有用。\n",
        "    ```python\n",
        "    with ipdb.launch_ipdb_on_exception():\n",
        "        main()\n",
        "        # 其他可能出錯的代碼...\n",
        "    ```\n",
        "    當 `main()` 函數或其他代碼塊拋出未捕獲的例外時，`ipdb` 會自動啟動，允許你立即檢查問題。\n",
        "\n",
        "這些是在命令行中使用 `ipdb` 的一些基本方法，有助於更有效地進行代碼調試。    "
      ],
      "metadata": {
        "id": "5Z17YJ0H0oNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#導入Pytorch模組\n",
        "import torch\n",
        "import torch.nn as nn                   #神經網絡（nn）\n",
        "import torch.optim as optim                #優化器（optim）\n",
        "from torch.utils.data import DataLoader, TensorDataset  #資料處理工具（DataLoader, TensorDataset）\n",
        "\n",
        "# 生成假資料\n",
        "#randn 函數返回一個張量，其元素在正態分佈中取樣，均值為 0，標準差為 1。(代表值在-1~1之間)\n",
        "n_samples = 1000\n",
        "X = torch.rand(n_samples, 10)               #shape=1000x10\n",
        "y = 3 * X.sum(dim=1) + 2 + torch.randn(n_samples)  # y = 3x + 2 + noise\n",
        "\n",
        "# 建立資料集和資料載入器\n",
        "#使用 DataLoader 進行批量處理，每次取 32 個樣本，並且打亂資料順序\n",
        "dataset = TensorDataset(X, y)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 定義一個簡單的 MLP 模型\n",
        "#模型包含兩個全連接層\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 5)     #將 10 維輸入轉換為 5 維\n",
        "        self.fc2 = nn.Linear(5, 1)      #將 5 維轉換為 1 維輸出\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))      #在兩層之間使用 ReLU 激活函數\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1xkglv6BO7ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化模型、損失函數和優化器\n",
        "model = SimpleMLP()\n",
        "criterion = nn.MSELoss()                #使用均方誤差損失函數（MSELoss）\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  #選擇 Adam 優化器進行模型參數的更新。學習率設置為 0.001\n",
        "\n",
        "# 訓練模型\n",
        "for epoch in range(100):\n",
        "    for batch_X, batch_y in dataloader:\n",
        "        # 前向傳播\n",
        "        # 將批次資料 batch_X 輸入模型，計算輸出結果 outputs，並根據預測值和真實值 batch_y 計算損失 loss\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 反向傳播和優化\n",
        "        # 清空梯度（optimizer.zero_grad()），進行反向傳播以計算梯度（loss.backward()），並使用優化器更新模型參數（optimizer.step()）\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/10], Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "KFZHIHXi2K2A",
        "outputId": "8b57e2c2-ddd2-4289-db99-73d4c87aadc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SimpleMLP' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c00acd85a05d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 初始化模型、損失函數和優化器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m#使用均方誤差損失函數（MSELoss）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#選擇 Adam 優化器進行模型參數的更新。學習率設置為 0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SimpleMLP' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model is on: {next(model.parameters()).device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LslKBxs22iXY",
        "outputId": "c827250a-f323-4006-af12-a9ae7d50873e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXnUuQqA2gT8",
        "outputId": "f90955fc-f9d1-4c4d-be36-c7a911ab5e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun 24 08:34:08 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dKL1Kwlq2SPY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}